Pequeno tutorial dos passos que foram necessários para rodar o MapReduce do Hadoop:

1 - Mudar o path do java em hadoop-env.sh

2 - startar o hdfs
$ sbin/start-dfs.sh

3 - crie um diretorio no hdfs
$ bin/hdfs dfs -mkdir /user

4 - colocar o arquivo de input dentro do hdfs
$ bin/hdfs -put github_links.txt /user/

5 - startar yarn
$ sbin/start-yarn.sh

6 - rode o mapreduce
 sudo bin/hadoop jar \ 
 share/hadoop/tools/lib/hadoop-streaming-2.7.4.jar \
 -mapper mapper.py \
 -reducer reducer.py -input /user/github_links.txt -output /user/reduced

7 - pega os resultados
$ bin/hdfs dfs -get /user/reduced .

PS: talvez seja necessário rodar alguns comandos com sudo, não lembro ao certo quais.
